{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        damage_grade\n",
      "0                NaN\n",
      "1                NaN\n",
      "2                NaN\n",
      "3                NaN\n",
      "4                NaN\n",
      "5                NaN\n",
      "6                NaN\n",
      "7                NaN\n",
      "8                NaN\n",
      "9                NaN\n",
      "10               NaN\n",
      "11               NaN\n",
      "12               NaN\n",
      "13               NaN\n",
      "14               NaN\n",
      "15               NaN\n",
      "16               NaN\n",
      "17               NaN\n",
      "18               NaN\n",
      "19               NaN\n",
      "20               NaN\n",
      "21               NaN\n",
      "22               NaN\n",
      "23               NaN\n",
      "24               NaN\n",
      "25               NaN\n",
      "26               NaN\n",
      "27               NaN\n",
      "28               NaN\n",
      "29               NaN\n",
      "...              ...\n",
      "421145           NaN\n",
      "421146           NaN\n",
      "421147           NaN\n",
      "421148           NaN\n",
      "421149           NaN\n",
      "421150           NaN\n",
      "421151           NaN\n",
      "421152           NaN\n",
      "421153           NaN\n",
      "421154           NaN\n",
      "421155           NaN\n",
      "421156           NaN\n",
      "421157           NaN\n",
      "421158           NaN\n",
      "421159           NaN\n",
      "421160           NaN\n",
      "421161           NaN\n",
      "421162           NaN\n",
      "421163           NaN\n",
      "421164           NaN\n",
      "421165           NaN\n",
      "421166           NaN\n",
      "421167           NaN\n",
      "421168           NaN\n",
      "421169           NaN\n",
      "421170           NaN\n",
      "421171           NaN\n",
      "421172           NaN\n",
      "421173           NaN\n",
      "421174           NaN\n",
      "\n",
      "[421175 rows x 1 columns]\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "    0.0   1.0  NaN \n",
      "0     1     0     0\n",
      "1     1     0     0\n",
      "2     1     0     0\n",
      "3     1     0     0\n",
      "4     1     0     0\n",
      "5     1     0     0\n",
      "6     1     0     0\n",
      "7     1     0     0\n",
      "8     1     0     0\n",
      "9     1     0     0\n",
      "    7.0    9.0    10.0   11.0   12.0   13.0   20.0   21.0   22.0   23.0  \\\n",
      "0      1      0      0      0      0      0      0      0      0      0   \n",
      "1      1      0      0      0      0      0      0      0      0      0   \n",
      "2      1      0      0      0      0      0      0      0      0      0   \n",
      "3      1      0      0      0      0      0      0      0      0      0   \n",
      "4      1      0      0      0      0      0      0      0      0      0   \n",
      "5      1      0      0      0      0      0      0      0      0      0   \n",
      "6      1      0      0      0      0      0      0      0      0      0   \n",
      "7      1      0      0      0      0      0      0      0      0      0   \n",
      "8      1      0      0      0      0      0      0      0      0      0   \n",
      "9      1      0      0      0      0      0      0      0      0      0   \n",
      "\n",
      "   ...     39.0   40.0   43.0   44.0   45.0   46.0   47.0   48.0   51.0  NaN    \n",
      "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "5  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "6  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "7  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "8  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "9  ...        0      0      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['damage_grade']\n",
    "y = pd.DataFrame(df, columns=columns)\n",
    "# y = pd.get_dummies(y, dummy_na=True)\n",
    "print(y)\n",
    "columns = ['has_geotechnical_risk_fault_crack',\n",
    "          'has_geotechnical_risk_flood',\n",
    "          'has_geotechnical_risk_land_settlement',\n",
    "          'has_geotechnical_risk_landslide',\n",
    "          'has_geotechnical_risk_liquefaction',\n",
    "          'has_geotechnical_risk_other',\n",
    "          'has_geotechnical_risk_rock_fall'\n",
    "          ]\n",
    "x = pd.DataFrame(df, columns=columns)\n",
    "\n",
    "column_has_repair_started = []\n",
    "for i in df.has_repair_started:\n",
    "    if i == 0.0 or i == 1.0:\n",
    "        column_has_repair_started.append(int(i))\n",
    "    else:\n",
    "        column_has_repair_started.append(0)\n",
    "print(column_has_repair_started[:10])\n",
    "has_repair_started = pd.DataFrame(column_has_repair_started)\n",
    "x = pd.concat([x, has_repair_started],axis=1) \n",
    "x = x.rename(columns={0: 'has_repair_started'})\n",
    "\n",
    "column_has_geotechnical_risk = []\n",
    "for i in df.has_geotechnical_risk:\n",
    "    if i == 0.0 or i == 1.0:\n",
    "        column_has_geotechnical_risk.append(int(i))\n",
    "    else:\n",
    "        column_has_geotechnical_risk.append(0)\n",
    "print(column_has_geotechnical_risk[:10])\n",
    "has_geotechnical_risk = pd.DataFrame(column_has_geotechnical_risk)\n",
    "x = pd.concat([x, has_geotechnical_risk],axis=1) \n",
    "x = x.rename(columns={0: 'has_geotechnical_risk'})\n",
    "\n",
    "has_geotechnical_risk = df.has_geotechnical_risk\n",
    "has_geotechnical_risk = pd.get_dummies(has_geotechnical_risk, dummy_na=True)\n",
    "print(has_geotechnical_risk[:10])\n",
    "x = pd.concat([has_geotechnical_risk, x],axis=1)\n",
    "\n",
    "district_id = df.district_id\n",
    "district_id = pd.get_dummies(district_id, dummy_na=True)\n",
    "print(district_id[:10])\n",
    "x = pd.concat([district_id, x],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_assesed                              object\n",
      "building_id                               object\n",
      "damage_grade                              object\n",
      "district_id                                int64\n",
      "has_geotechnical_risk                    float64\n",
      "has_geotechnical_risk_fault_crack          int64\n",
      "has_geotechnical_risk_flood                int64\n",
      "has_geotechnical_risk_land_settlement      int64\n",
      "has_geotechnical_risk_landslide            int64\n",
      "has_geotechnical_risk_liquefaction         int64\n",
      "has_geotechnical_risk_other                int64\n",
      "has_geotechnical_risk_rock_fall            int64\n",
      "has_repair_started                       float64\n",
      "vdcmun_id                                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631761, 44)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 50)                2250      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 29)                1479      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 17)                510       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 6)                 108       \n",
      "=================================================================\n",
      "Total params: 4,347\n",
      "Trainable params: 4,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=44, activation='relu'))\n",
    "model.add(Dense(29, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(17, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x[:500000]\n",
    "train_labels = y[:500000]\n",
    "test_data = x[500000:]\n",
    "test_labels = y[500000:]\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500000 samples, validate on 131761 samples\n",
      "Epoch 1/10\n",
      "500000/500000 [==============================] - 19s 38us/step - loss: 1.3521 - acc: 0.4167 - val_loss: 1.3236 - val_acc: 0.4296\n",
      "Epoch 2/10\n",
      "500000/500000 [==============================] - 19s 38us/step - loss: 1.3325 - acc: 0.4267 - val_loss: 1.3222 - val_acc: 0.4318\n",
      "Epoch 3/10\n",
      "500000/500000 [==============================] - 19s 37us/step - loss: 1.3302 - acc: 0.4276 - val_loss: 1.3209 - val_acc: 0.4311\n",
      "Epoch 4/10\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 1.3287 - acc: 0.4285 - val_loss: 1.3204 - val_acc: 0.4309\n",
      "Epoch 5/10\n",
      "500000/500000 [==============================] - 22s 44us/step - loss: 1.3273 - acc: 0.4285 - val_loss: 1.3198 - val_acc: 0.4323\n",
      "Epoch 6/10\n",
      "500000/500000 [==============================] - 19s 39us/step - loss: 1.3267 - acc: 0.4289 - val_loss: 1.3195 - val_acc: 0.4324\n",
      "Epoch 7/10\n",
      "500000/500000 [==============================] - 19s 39us/step - loss: 1.3260 - acc: 0.4297 - val_loss: 1.3203 - val_acc: 0.4311\n",
      "Epoch 8/10\n",
      "500000/500000 [==============================] - 19s 37us/step - loss: 1.3257 - acc: 0.4291 - val_loss: 1.3192 - val_acc: 0.4328\n",
      "Epoch 9/10\n",
      "500000/500000 [==============================] - 20s 40us/step - loss: 1.3250 - acc: 0.4293 - val_loss: 1.3192 - val_acc: 0.4324\n",
      "Epoch 10/10\n",
      "500000/500000 [==============================] - 19s 39us/step - loss: 1.3249 - acc: 0.4293 - val_loss: 1.3197 - val_acc: 0.4328\n",
      "Accuracy: 43.28%\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_labels, validation_data=(test_data, test_labels), epochs=10, batch_size=100)\n",
    "scores = model.evaluate(test_data, test_labels, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/test.csv')\n",
    "columns = ['has_geotechnical_risk_fault_crack',\n",
    "          'has_geotechnical_risk_flood',\n",
    "          'has_geotechnical_risk_land_settlement',\n",
    "          'has_geotechnical_risk_landslide',\n",
    "          'has_geotechnical_risk_liquefaction',\n",
    "          'has_geotechnical_risk_other',\n",
    "          'has_geotechnical_risk_rock_fall'\n",
    "          ]\n",
    "xnew = pd.DataFrame(df, columns=columns)\n",
    "\n",
    "column_has_repair_started = []\n",
    "for i in df.has_repair_started:\n",
    "    if i == 0.0 or i == 1.0:\n",
    "        column_has_repair_started.append(int(i))\n",
    "    else:\n",
    "        column_has_repair_started.append(0)\n",
    "has_repair_started = pd.DataFrame(column_has_repair_started)\n",
    "xnew = pd.concat([xnew, has_repair_started],axis=1) \n",
    "xnew = xnew.rename(columns={0: 'has_repair_started'})\n",
    "\n",
    "column_has_geotechnical_risk = []\n",
    "for i in df.has_geotechnical_risk:\n",
    "    if i == 0.0 or i == 1.0:\n",
    "        column_has_geotechnical_risk.append(int(i))\n",
    "    else:\n",
    "        column_has_geotechnical_risk.append(0)\n",
    "has_geotechnical_risk = pd.DataFrame(column_has_geotechnical_risk)\n",
    "xnew = pd.concat([has_geotechnical_risk, xnew],axis=1) \n",
    "xnew = xnew.rename(columns={0: 'has_geotechnical_risk'})\n",
    "\n",
    "has_geotechnical_risk = df.has_geotechnical_risk\n",
    "has_geotechnical_risk = pd.get_dummies(has_geotechnical_risk, dummy_na=True)\n",
    "xnew = pd.concat([has_geotechnical_risk, xnew],axis=1)\n",
    "\n",
    "district_id = df.district_id\n",
    "district_id = pd.get_dummies(district_id, dummy_na=True)\n",
    "xnew = pd.concat([district_id, xnew],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.49538964e-01   3.12375098e-01   3.64545494e-01   3.76503021e-01\n",
      "    8.56564522e-01   2.90691832e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]\n",
      " [  1.35415509e-01   1.66470096e-01   2.91241467e-01   3.84356439e-01\n",
      "    9.15508449e-01   3.85149634e-10]]\n"
     ]
    }
   ],
   "source": [
    "print(ynew[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
